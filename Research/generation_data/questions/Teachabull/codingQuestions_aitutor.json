{
    "questions": [
        {
            "subject": 1,
            "type": 3,
            "data": {
                "data": "In the context of processing tweets or social media text, write a Python function `extract_hashtags` that takes a string as an input and returns a list of hashtags in the text. You are required to use regular expressions in your solution. Consider that a hashtag is defined as a string that begins with a hash symbol (#) and is followed by alphanumeric characters without spaces.",
                "boilerplate": "def extract_hashtags(text):\n    # TODO: Your code here\n    pass",
                "test_cases_script": "assert extract_hashtags(\"Loving the #AI and #NLP talks at the conference!\") == [\"#AI\", \"#NLP\"]\nassert extract_hashtags(\"This is a #great_day!\") == [\"#great_day\"]\nassert extract_hashtags(\"Hello world!\") == []",
                "concepts": [
                    "Regular Expressions",
                    "Applications of Regular Expressions in NLP"
                ]
            }
        },
        {
            "subject": 1,
            "type": 0,
            "data": {
                "data": "Implement a function `count_vowels` in Python that takes a string input and returns the number of vowels in the string. Consider the following vowels: a, e, i, o, u, and their uppercase counterparts.",
                "rubric": "Rubric: [1 Point] Correct implementation of the function; [1 Point] Correct count of vowels; [1 Point] Correct handling of uppercase vowels; [1 Point] Clean, readable code with appropriate comments.",
                "concepts": [
                    "Regular Expressions"
                ]
            }
        },
        {
            "subject": 1,
            "type": 3,
            "data": {
                "data": "Write a Python function to calculate the Edit Distance between two strings using the Levenshtein distance algorithm. Your function should take two arguments (string1, string2) and return the minimum number of operations required to convert string1 into string2. You can limit your solution to insertions, deletions, and substitutions as the allowed edit operations.",
                "boilerplate": "def edit_distance(str1, str2):\n    # Your code here\n    pass",
                "test_cases_script": "assert edit_distance('kitten', 'sitting') == 3\nassert edit_distance('intention', 'execution') == 5\nassert edit_distance('algorithm', 'altruistic') == 6",
                "concepts": [
                    "Edit Distance",
                    "Applications of Edit Distance Algorithm in NLP"
                ]
            }
        },
        {
            "subject": 1,
            "type": 3,
            "data": {
                "data": "Write a Python function named `lemmatize_tokens` that takes a string as input and returns a list of lemmatized tokens. Your implementation should tokenize the text and then apply lemmatization to each token.",
                "boilerplate": "def lemmatize_tokens(text):\n    # Your code here\n    # You may use NLTK library for tokenizing and lemmatization\n\n    pass  # Replace with your implementation",
                "test_cases_script": "sample_text = \"The striped bats are hanging on their feet for best\"\nassert lemmatize_tokens(sample_text) == [\"The\", \"striped\", \"bat\", \"be\", \"hanging\", \"on\", \"their\", \"foot\", \"for\", \"best\"], \"Test case failed!\"",
                "concepts": [
                    "Natural Language Processing (NLP)",
                    "Tokenization of Text",
                    "Lemmatization"
                ]
            }
        },
        {
            "subject": 1,
            "type": 3,
            "data": {
                "data": "Write a Python function that uses regular expressions to count the number of times a specific word appears in a given text.",
                "boilerplate": "import re\n\ndef count_word_occurrences(word, text):\n\t# TODO: Complete the function\n\tpass",
                "test_cases_script": "text = '''Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum auctor euismod nunc, nec lacinia libero ultrices nec. Nulla vitae sagittis ipsum. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Morbi vitae neque viverra, euismod nisl in, tristique odio. Nulla facilisi. Sed vehicula lorem massa, a ultrices quam iaculis et. Donec pretium viverra accumsan. Proin in lorem velit. Integer nec interdum enim, sit amet condimentum libero. Phasellus sagittis, sapien sed dapibus imperdiet, purus metus bibendum mauris, quis congue ipsum eros quis nibh.'''\n\nassert count_word_occurrences('Lorem', text) == 1\nassert count_word_occurrences('semper', text) == 0\nassert count_word_occurrences('amet', text) == 2",
                "concepts": [
                    "Regular Expressions",
                    "Uses of Regular Expressions in NLP",
                    "Basic Syntax and Operators of Regular Expressions"
                ],
                "teaching_note": "Regular expressions are a powerful tool for pattern matching in text. In this question, you will use regular expressions to count the number of times a specific word appears in a given text. Remember to use the re module in Python to access the regular expression functions. You can use the re.findall() function to find all occurrences of the word in the text and then use the len() function to count the number of matches."
            }
        }
    ],
    "current_obj_idx": -1,
    "num_questions": 5
}
